# 架构设计

本文档详细阐述 `Second-Me` 项目的系统架构，包括核心组件、它们之间的交互方式以及数据流转过程。

## 分层记忆模型 (Hierarchical Memory Model - HMM) 架构

HMM 是 Second-Me 项目记忆处理的核心架构，由三个层次 (L0、L1、L2) 组成，每层承担不同的功能职责，共同实现了个性化 AI 助手的记忆处理与个性化对齐。

### 层级结构与功能

**L0 层（输入处理与初步洞察）**
*   **核心功能：** 处理多模态输入数据，利用 LLM 进行初步分析和语义理解。
*   **处理流程：** 通过 `Insighter` 和 `Summarizer` 处理图像、音频、文档等不同类型的输入。
*   **输出：** 生成标准化的原子记忆单元 (`Note` 对象)，包含标题、内容、洞察和关键词。

**L1 层（特征提取与结构化记忆）**
*   **核心功能：** 聚合 L0 的输出，进行跨时间和跨输入的整合分析。
*   **关键模块：**
    *   `TopicsGenerator`：聚类并生成主题标签。
    *   `ShadeGenerator`：生成用户特征描述。
    *   `BioGenerator`：构建用户整体画像。
*   **输出：** 结构化的用户表征，包括主题聚类和用户 `Bio`。

**L2 层（个性化对齐与模型微调）**
*   **核心功能：** 利用 L1 的结构化记忆进行模型个性化对齐。
*   **技术方法：** 使用 SFT 和 DPO 对基础 LLM 进行微调。
*   **数据流程：** 通过 `L2DataProcessor` 处理多种来源数据，生成训练数据集。
*   **输出：** 经过个性化微调的语言模型。

### 数据流转过程

整个系统的数据流是自下而上的：

1.  **用户输入 -> L0：** 处理单一输入，生成标准化 `Note`。
2.  **L0 -> L1：** 聚合 `Note`，进行聚类和特征提取，更新用户 `Bio`。
3.  **L1 (及 GraphRAG) -> L2 数据流水线：** L1 输出及 GraphRAG 提取的实体信息被送入 `L2DataProcessor`。
4.  **L2 数据流水线 -> L2 训练：** `L2DataProcessor` 生成格式化的 SFT/DPO 数据集。
5.  **L2 训练 -> 个性化模型：** 通过 SFT/DPO 微调基础 LLM，产出最终的个性化模型。

### 典型应用场景：处理用户笔记

当用户输入一条关于"学习 Python 异步编程"的笔记时：

1.  **L0** 将其处理成带有洞察和关键词的标准化 `Note`。
2.  **L1** 会将此 `Note` 与相关内容聚类，提取"技术学习者"等用户特征并更新 `Bio`。
3.  **L2** 利用这些信息（以及可能通过 GraphRAG 提取的 `asyncio` 实体）生成训练数据，教会模型理解用户的编程兴趣。
4.  最终**个性化模型**能够根据用户的特定兴趣和背景，提供相关的、个性化的回答。

此架构通过三层渐进式处理，实现了从原始输入到个性化模型的完整转化，使 AI 助手能够深入理解用户并提供符合用户思维方式的回应。 